{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSTALLING DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install dask.dataframe\n",
    "pip install dask.array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_data=pd.read_csv("Competition_Data.csv\")\n",
    "pricing_data.head()\n",
    "pricing_data.set_index('Index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA(VISUALISATIONS+TREND ANALYSIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRICE DISTRIBUTION VISUALISATION(SELF VS COMPETITION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(pricing_data['Price'],bins=30,alpha=0.7,label='Your Store')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Price Distribution - Your Store')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(pricing_data['Competition_Price'],bins=30,alpha=0.7,color='green',label='Competition')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Price Distribution - Competition')\n",
    "plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRICING VS SALES AMOUNT COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(pricing_data['Price'], pricing_data['Sales_Amount'], alpha=0.6, label='Your Store')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Sales Amount')\n",
    "plt.title('Price vs Sales Amount - Our Store')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(pricing_data['Competition_Price'], pricing_data['Sales_Amount'], alpha=0.6, color='green', label='Competition')\n",
    "plt.xlabel('Competition Price')\n",
    "plt.ylabel('Sales Amount')\n",
    "plt.title('Competition Price vs Sales Amount')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATETIME CONVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_data['Fiscal_Week_ID']=pd.to_datetime(pricing_data['Fiscal_Week_ID']+ '-1',format='%Y-%U-%w')\n",
    "print(pricing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FISCAL WEEK TURNOVER TREND ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_prices=pricing_data.groupby('Fiscal_Week_ID').agg({\n",
    "    'Price' : 'mean',\n",
    "    'Competition_Price' : 'mean'\n",
    "}).reset_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(weekly_prices['Fiscal_Week_ID'], weekly_prices['Price'], label='Our Store', marker='o')\n",
    "plt.plot(weekly_prices['Fiscal_Week_ID'], weekly_prices['Competition_Price'], label='Competition', marker='o', color='orange')\n",
    "\n",
    "plt.xlabel('Fiscal Week')\n",
    "plt.ylabel('Average Price')\n",
    "plt.title('Price Changes Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRICE ELASTICITY PATTERN ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_data['price_change']=pricing_data['Price'].pct_change()\n",
    "pricing_data['qty_change'] = pricing_data['Item_Quantity'].pct_change()\n",
    "\n",
    "pricing_data['elasticity'] = pricing_data['qty_change'] / pricing_data['price_change']\n",
    "\n",
    "pricing_data.replace([float('inf'), -float('inf')], float('nan'), inplace=True)\n",
    "pricing_data.dropna(subset=['elasticity'], inplace=True)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(pricing_data['Fiscal_Week_ID'],pricing_data['elasticity'],marker='o',linestyle='-',color='maroon')\n",
    "plt.axhline(0, color='grey', linewidth=0.8)\n",
    "plt.xlabel('Fiscal Week')\n",
    "plt.ylabel('Price Elasticity of Demand')\n",
    "plt.title('Price Elasticity of Demand Over Time')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INVENTORY STOCKUP VS SALES GENERATION ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sales_your_store=pricing_data['Sales_Amount'].sum()\n",
    "total_sales_competition=(pricing_data['Competition_Price']*pricing_data['Item_Quantity']).sum()\n",
    "\n",
    "total_qty_your_store = pricing_data['Item_Quantity'].sum()\n",
    "total_qty_competition = pricing_data['Item_Quantity'].sum()  # assuming quantities sold are the same for comparison\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    'Metric': ['Total Sales Amount', 'Total Quantity Sold'],\n",
    "    'Your Store': [total_sales_your_store, total_qty_your_store],\n",
    "    'Competition': [total_sales_competition, total_qty_competition]\n",
    "})\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRICE BRACKET WISE SALES ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define price brackets\n",
    "bins = [0, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
    "labels = ['0-50', '51-100', '101-150', '151-200', '201-250', '251-300', '301-350', '351-400', '401-450', '451-500']\n",
    "\n",
    "# create price brackets for both your store and competition\n",
    "pricing_data['price_bracket'] = pd.cut(pricing_data['Price'], bins=bins, labels=labels, right=False)\n",
    "pricing_data['competition_price_bracket'] = pd.cut(pricing_data['Competition_Price'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# calculate sales amount by price bracket for your store\n",
    "sales_by_bracket_your_store = pricing_data.groupby('price_bracket')['Sales_Amount'].sum().reset_index()\n",
    "sales_by_bracket_your_store.columns = ['Price Bracket', 'Your Store Sales Amount']\n",
    "\n",
    "# calculate sales amount by price bracket for competition\n",
    "pricing_data['competition_sales_amt'] = pricing_data['Competition_Price'] * pricing_data['Item_Quantity']\n",
    "sales_by_bracket_competition = pricing_data.groupby('competition_price_bracket')['competition_sales_amt'].sum().reset_index()\n",
    "sales_by_bracket_competition.columns = ['Price Bracket', 'Competition Sales Amount']\n",
    "\n",
    "sales_by_bracket = pd.merge(sales_by_bracket_your_store, sales_by_bracket_competition, on='Price Bracket')\n",
    "\n",
    "sales_by_bracket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(pricing_data['Price_avg']))\n",
    "print(pricing_data['Price_avg'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA SEGMENTATION FOR ELASTICITY SENSITIVITY ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average price and total quantity sold for each item\n",
    "item_summary = pricing_data.groupby('Item_ID').agg({\n",
    "    'Price': 'mean',\n",
    "    'Item_Quantity': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Check the structure of item_summary\n",
    "print(item_summary.head())\n",
    "\n",
    "# Merge the item summary back to the main dataset, but only merge necessary columns to avoid duplication\n",
    "pricing_data = pd.merge(\n",
    "    pricing_data, \n",
    "    item_summary[['Item_ID', 'Price', 'Item_Quantity']],  # Only merge necessary columns\n",
    "    on='Item_ID', \n",
    "    suffixes=('', '_avg')\n",
    ")\n",
    "\n",
    "# After merging, check for duplicate columns\n",
    "print(pricing_data.columns)\n",
    "\n",
    "# If there are still duplicate columns, explicitly drop them\n",
    "# This step will only keep one copy of each duplicated column\n",
    "pricing_data = pricing_data.loc[:, ~pricing_data.columns.duplicated()]\n",
    "\n",
    "# Ensure 'Price_avg' is a numeric column and clean any NaN values\n",
    "pricing_data['Price_avg'] = pd.to_numeric(pricing_data['Price_avg'], errors='coerce')\n",
    "pricing_data = pricing_data.dropna(subset=['Price_avg'])\n",
    "\n",
    "# Define segments based on average price\n",
    "bins = [0, 50, 150, 300]\n",
    "labels = ['Low', 'Medium', 'High']\n",
    "\n",
    "# Ensure 'Price_avg' is correctly structured and apply segmentation\n",
    "pricing_data['segment'] = pd.cut(pricing_data['Price_avg'], bins=bins, labels=labels)\n",
    "\n",
    "# Continue with the rest of elasticity calculations\n",
    "segments = pricing_data['segment'].unique()\n",
    "elasticity_data = []\n",
    "\n",
    "for segment in segments:\n",
    "    segment_data = pricing_data[pricing_data['segment'] == segment]\n",
    "    segment_data['price_change'] = segment_data['Price'].pct_change()\n",
    "    segment_data['qty_change'] = segment_data['Item_Quantity'].pct_change()\n",
    "    segment_data['elasticity'] = segment_data['qty_change'] / segment_data['price_change']\n",
    "    segment_data.replace([float('inf'), -float('inf')], float('nan'), inplace=True)\n",
    "    avg_elasticity = segment_data['elasticity'].mean()\n",
    "    elasticity_data.append({'segment': segment, 'avg_elasticity': avg_elasticity})\n",
    "\n",
    "elasticity_df = pd.DataFrame(elasticity_data)\n",
    "elasticity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DYNAMIC PRICING VS SEASONAL PRICING IMPACT UPON SALES ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the dataset for simulation\n",
    "dynamic_pricing_data = pricing_data.copy()\n",
    "\n",
    "# apply dynamic pricing rules\n",
    "dynamic_pricing_data.loc[dynamic_pricing_data['segment'] == 'Medium', 'dynamic_price'] = dynamic_pricing_data['Price'] * 1.05\n",
    "dynamic_pricing_data.loc[dynamic_pricing_data['segment'] == 'High', 'dynamic_price'] = dynamic_pricing_data['Price'] * 0.90\n",
    "\n",
    "# calculate new sales amounts based on dynamic prices\n",
    "dynamic_pricing_data['dynamic_sales_amt'] = dynamic_pricing_data['dynamic_price'] * dynamic_pricing_data['Item_Quantity']\n",
    "\n",
    "# compare total sales amount between existing and dynamic pricing\n",
    "total_sales_existing = pricing_data['Sales_Amount'].sum()\n",
    "total_sales_dynamic = dynamic_pricing_data['dynamic_sales_amt'].sum()\n",
    "\n",
    "# compare total quantity sold between existing and dynamic pricing\n",
    "total_qty_existing = pricing_data['Item_Quantity'].sum()\n",
    "total_qty_dynamic = dynamic_pricing_data['Item_Quantity'].sum()  # quantity sold remains the same for comparison\n",
    "\n",
    "comparison_summary = pd.DataFrame({\n",
    "    'Metric': ['Total Sales Amount', 'Total Quantity Sold'],\n",
    "    'Existing Pricing': [total_sales_existing, total_qty_existing],\n",
    "    'Dynamic Pricing': [total_sales_dynamic, total_qty_dynamic]\n",
    "})\n",
    "\n",
    "comparison_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DASK IMPLEMENTATION FOR FASTER COMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "# Convert Pandas DataFrame to Dask DataFrame\n",
    "dynamic_pricing_data_dd = dd.from_pandas(pricing_data, npartitions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_pricing_data_dd['dynamic_price'] = da.where(\n",
    "    dynamic_pricing_data_dd['segment'] == 'Medium',  # Condition for Medium\n",
    "    dynamic_pricing_data_dd['Price'] * 1.05,         # Apply 5% increase for Medium\n",
    "    da.where(                                     # Nested condition for High\n",
    "        dynamic_pricing_data_dd['segment'] == 'High',\n",
    "        dynamic_pricing_data_dd['Price'] * 0.90,     # Apply 10% decrease for High\n",
    "        dynamic_pricing_data_dd['Price']             # Leave unchanged for other segments\n",
    "    )\n",
    ")\n",
    "\n",
    "# Compute the final result (this triggers computation)\n",
    "dynamic_pricing_data = dynamic_pricing_data_dd.compute()\n",
    "dynamic_pricing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINAL PRICING BASED UPON ELASTICITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_data['dynamic_price'] = dynamic_pricing_data['dynamic_price']\n",
    "pricing_data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
